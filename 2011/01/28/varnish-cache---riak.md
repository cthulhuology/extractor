Varnish Cache + Riak
====================

A common problem when building applications with something as simple as <a HREF=http://basho.com/riaksearch.html>Riak</a> is that matching your cannonical name for a resource to a suitable key=value store object on the backend can be hard. Generally, using a directly accessible Riak cluster is a bad idea(tm). Users can PUT data and replace your entire site in a matter of seconds. In order to work around these limitations Basho recommends hiding it behind a caching proxy like <a HREF=http://varnish-cache.org>Varnish</a>. <br /><br />Setting up varnish is rather straight forward, but configuring it to power your application can be daunghting. The VCL configuration language even allows embedding C code in your configuration. It is not so much a config file, as extension program.  This however means you can easily build custom backend routers for your applications that map incoming requests to multiple backend services, as well as, request rewriting to map external urls to internal resources.<br /><br />If you download the current Riak Search tarball and build from source:<br /><br /><pre><br /> # wget <a href=http://downloads.basho.com/riak-search/CURRENT/riak_search-0.14.0-1.tar.gz">http://downloads.basho.com/riak-search/CURRENT/riak_search-0.14.0-1.tar.gz</a><br /> # tar zxvf riak_search-0.14.0-1.tar.gz<br /> # cd riak_search-0.14.0<br /> # make all<br /> # make devrel<br /></pre><br /><br />It will build the application and a development instance with 3 independent servers in the dev directory.  By default it is configured to run on ports 8091, 8092, and 8093 for instance dev1, dev2, and dev3 respectively.   You can then build Varnish from source as well:<br /><br /><pre><br /> # wget http://repo.varnish-cache.org/source/varnish-2.1.5.tar.gz<br /> # tar zxvf  varnish-2.1.5.tar.gz<br /> # cd varnish-2.1.5<br /> # ./configure<br /> # make<br /> # sudo make install<br /></pre><br /><br />At this point you&#39;ll have everything you need to build a cluster of servers, but for now we&#39;re just going to configure it to run locally on our development box.  What I personally like to do is to move my development riak servers and my varnish config into a new directory:<br /><br /><pre><br /> # mkdir ~/Servers/<br /> # cp -r ~/riak_search-0.14.0/dev/* ~/Servers<br /> # cd ~/Servers<br /></pre><br /><br />This works because Riak&#39;s builds are fully self contained, and can be simply tarred up or rsynced to another server and run pretty much as is (with maybe a change to the app.config and vm.args files to set the correct ip address and instance name).<br />To make working with the servers, bringing the up and down I generally write a little utility script:<br /><br /><pre><br />  #!/bin/bash<br />  ulimit -n 1024<br />  for I in 1 2 3; do<br />          ./dev$I/bin/riaksearch $1;<br />  done<br /></pre><br /><br />Which just lets me run the same commands on all 3 servers.  The ulimit change is helpful if you&#39;re running on a system like MacOS X which has an abysmal open file limit by default (and even worse concurrent process limit).  The last administrative task is to join dev2 and dev3 to the ring in dev1:<br /><br /><pre><br />  for I in 2 3; do<br />          ./dev$I/bin/riaksearch-admin join dev1@127.0.0.1;<br />  done<br /></pre><br /><br />With the three nodes all in the same ring, we can put stuff inside of it using curl.  Riak keeps the Content-Type you give it so be certain to set the right MIME type for each file.  The next step is to configure varnish to act as a proper proxy that can also purge its caches when we update some internal representation.  The first helper we&#39;ll write is a <b>proxy</b> script to launch varnish:<br /><br /><pre><br />#!/bin/bash<br />sudo varnishd -f riak.vcl -T:9000<br /></pre><br /><br />Here we&#39;re running varnishd with the riak.vcl file as its config and the admin interface running on port 9000 on localhost.  We can write a reload script too, in order to make futzing with our config file easier like so:<br /><br /><pre><br />#!/bin/bash<br />CWD=`pwd`<br />UUID=`uuid`<br />varnishadm -T:9000 "vcl.load $UUID $CWD/riak.vcl"<br />varnishadm -T:9000 "vcl.use $UUID"<br /></pre><br /><br />If your system doesn&#39;t have <b>uuid</b> look to see if you have <b>uuidgen</b> which is basically equivalent.  This will be very useful as you make changes and test your configs.  It is also helpful when you want to update your configs gracefully and have a way to revert.  But the first bit to add in your new <b>riak.vcl</b> is a directive to have varnish talk to all 3 backends in a round-robin fashion:<br /><br /><pre><br />director riak round-robin {<br />        { .backend  =  { .host = "127.0.0.1"; .port = "8091"; .probe = { .url = "/ping"; .threshold = 3; }}}<br />        { .backend  =  { .host = "127.0.0.1"; .port = "8092"; .probe = { .url = "/ping"; .threshold = 3; }}}<br />        { .backend  =  { .host = "127.0.0.1"; .port = "8093"; .probe = { .url = "/ping"; .threshold = 3; }}}<br />}<br /></pre><br /><br />This directive sets up all 3 nodes to talk to varnish, with a health check pinging the "/ping" interface about once every 5 seconds.  If any one node goes down, varnish will route around it until it comes back up as healthy in the ping checks.  If you run <b>varnishlog</b> you will see a ton of activity like:<br /><br /><pre><br />    0 Backend_health - riak[0] Still healthy 4--X-RH 4 3 4 0.003052 0.003220 HTTP/1.1 200 OK<br />    0 Backend_health - riak[2] Still healthy 4--X-RH 4 3 4 0.003596 0.002407 HTTP/1.1 200 OK<br />    0 Backend_health - riak[1] Still healthy 4--X-RH 4 3 4 0.001998 0.002764 HTTP/1.1 200 OK<br /></pre><br /><br />which is exactly what you want to see.  Once you have that bit done, the next bit is to establish an ACL to hide the bits of the Riak interface from the public we really don&#39;t want exposed:<br /><br /><pre><br />acl admin {<br />        "127.0.0.1";<br />        "192.168.1.0"/24;<br />}<br /></pre><br /><br />This will restrict access to our local box and network.  You can add additional ACLs to control access to particular bits of your Riak key value store, such as removing the ability to perform map-reduce queries, access the Solr interface, or simply do PUTs, POSTs, and DELETEs on specific buckets.  The place that you want to set up your routing and access logic is in the <b>vcl_recv</b> subroutine like this:<br /><br /><pre><br />sub vcl_recv {<br />        unset req.http.cookie;<br />        if (req.url ~ "^http://") {<br />                set req.url = regsub(req.url, "http://[^/]*", "");<br />        }<br />        if (req.request == "PUT" || req.request == "DELETE" || req.request == "POST")  {<br />                purge("req.url ~ " req.url);<br />                return(pass);<br />        }<br />        if (req.url ~ "^/admin/") {<br />                if (!client.ip  ~ admin) {<br />                        error 403 "Access Denied";<br />                }<br />                if (req.url ~ "^/admin/ping") {<br />                        set req.url =  regsub(req.url, "^/admin","");<br />                }<br />                if (req.url ~ "^/admin/stats") {<br />                        set req.url =  regsub(req.url, "^/admin","");<br />                }<br />        } elsif (req.url ~ "^/objects/") {<br />                set req.url = regsub(req.url, "^/objects/", "/riak/objects");<br />        } elsif (req.url ~ "^/riak/") {<br />                // do nothing we&#39;re cool!<br />        } elseif (req.url ~ "^/$") {<br />                set req.url = regsub(req.url, "^/$", "/riak/site/index.html");<br />        } else {<br />                set req.url = regsub(req.url, "^/", "/riak/site/");<br />        }<br />        return(lookup);<br />}<br /></pre><br /><br />In this example, I&#39;ve removed all cookies from the request.  Cookies break cache-ability and we aren&#39;t going to do anything with them anyways on the backend.  We also normalize the URLs to account for buggy clients which incorrectly embed the http protocol directive in the path.  Then we direct varnish to purge cache elements when we PUT, POST, or DELETE some entry and pass the request directly on to Riak bypassing further processing.  Finally, we rewrite the addresses mapping everything in the /admin/ path to an ACL controlled set of paths that let us get at the health and stats for any backend.  We also direct anything in a top level /objects/ directory to a /riak/objects/ bucket making it easy to pass UUID named objects to Riak and consume on the client.  The /riak/ path is passed through as is to make populating entries in new buckets straight forward.  Finally, in order to serve a static site out of Riak, we&#39;ve mapped "/" to the <b>site</b> bucket and specifically the index.html file.  Finally, for all paths that remain, we map those to entities in the <b>site</b> bucket allowing us to dump all our CSS, HTML, Javascript, images, videos, and other garbage directly into that bucket. For all these things we explicitly look up the values in cache before going to Riak.<br /><br />Since varnish is a caching proxy, it is handy to add some cache control directives to the configuration, and some debugging info to help us identify if our caching is working.  We can do this by modifying the <b>vcl_fetch</b> subroutine:<br /><br /><pre><br />sub vcl_fetch {<br />        if (!beresp.cacheable) {<br />                set beresp.http.X-Cacheable = "NO:Not Cacheable";<br />        } elsif ( beresp.http.Cache-Control ~ "private") {<br />                set beresp.http.X-Cacheable = "NO:Cache-Control=private";<br />                return(pass);<br />        } else {<br />                unset beresp.http.expires;<br />                set beresp.http.cache-control = "max-age = 900";<br />                set beresp.ttl = 1w;<br />                set beresp.http.magicmarker = "1";<br />                set beresp.http.X-Cacheable = "YES";<br />        }<br />}<br /></pre><br /><br />In this section, we&#39;re setting the X-Cacheable header on the response to provide more information about how varnish is caching the results.  In the case of things that are not cacheable, we pass those right back to the user.  Otherwise, we override the expiry times and setup a new TTL of 1w to keep the item in varnish cache for 1 week.  We also add a cache-control header so that the client doesn&#39;t attempt to redownload again for 15 minutes.  The magicmarker is a flag set so we can reset the document age to 0 in the <b>vcl_deliver</b> subroutine for content we are caching for a long time:<br /><br /><pre><br />sub vcl_deliver {<br />        if (resp.http.magicmarker) {<br />                unset resp.http.magicmarker;<br />                set resp.http.age = "0";<br />        }<br />}<br /></pre><br /><br />This helps force the browser to not check again for the full length of our cache-control header.  And now we&#39;re done!  We can load up our initial homepage into the site using <b>curl</b> as follows:<br /><br /><pre><br /># curl -X PUT http://127.0.0.1/riak/site/index.html -H "Content-type: text/html" --data-binary @index.html<br /></pre><br /><br />where <i>index.html</i> is a file that contains the HTML for our home page.  Because Riak handles most of the important bits for us, and varnish handles the routing and caching for us, we can then focus on just building the pieces of our applications that make our site interesting to the user.  Take for example trivial things like gzip encoding content.  When I ran the above curl command as part of my deployment script, it took a 8138 byte HTML file, and loaded it into the key value store replacing the old value.  The vcl config purged the cache, and reloading the home page returned these headers in the result:<br /><br /><pre><br />Age:0<br />Cache-Control:max-age = 900<br />Connection:keep-alive<br />Content-Encoding:gzip<br />Content-Length:2316<br />Content-Type:text/html<br />Date:Sat, 29 Jan 2011 03:37:41 GMT<br />Etag:1obS1uJRzaR7IrjLL6m014<br />Last-Modified:Sat, 29 Jan 2011 03:37:31 GMT<br />Link:</riak/site>; rel="up"<br />Server:MochiWeb/1.1 WebMachine/1.7.2 (participate in the frantic)<br />Vary:Accept-Encoding<br />Via:1.1 varnish<br />X-Cacheable:YES<br />X-Riak-Vclock:a85hYGDgzmDKBVIsrN/5TmQwJTLmsTIw/tt+jA8izNacxCrONQUqEYOQYGHJtK/GFAaqZ1++qhUqkc6wA66e8epnRkxhoHrmLLPXUIktSOqZ+XPnYAoD1TM80iyCSqiwI9Szcp5pwyLMsOuWK1S4mh3ZGBblx87IElkA<br />X-Varnish:704000027<br /></pre><br /><br />Notice that gzip encoding was provided, shrinking the payload to 2316 bytes, and proper Last-Modified, Date, Cache-Control, and Etag entries were generated.  The mime type also was preserved from my initial post, meaning that I can ensure that things such as HTML5 MANIFEST files can be delivered with the proper mime type:<br /><br /><pre><br /># curl -X PUT http://127.0.0.1/riak/site/MANIFEST -H "Content-type: text/cache-manifest" --data-binary @MANIFEST<br /></pre><br /><br />When combined with the caching proxy, the high performance of the Riak cluster itself, and proper caching settings on the client side, we have a powerful infrastructure on which to build highly scalable applications.  More over, we haven&#39;t even touched the incredibly cool things one can do with search and map/reduce on the Riak cluster, or building complex mappings using the links and key filters.<br /><br />The primary reason I&#39;m focusing on making Phos a much more usable tool for delivering reusable web widgets is that this stuff scales even better when your rendering and application logic is also shifted to the client side.  Your users all have perfectly serviceable machines on which they will view and interact with your site or application.  It is about time you started to rely on them as a natural extension of your cloud.  This infrastructure simply helps make it easier to synchronize across multiple clients and versions of your application, with minimal investment in a cloud of your own.